{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Customer Database\n",
    "**This is the first of three mandatory projects to be handed in as part of the assessment for the course 02807 Computational Tools for Data Science at Technical University of Denmark, autumn 2019.**\n",
    "\n",
    "#### Practical info\n",
    "- **The project is to be done in groups of at most 3 students**\n",
    "- **Each group has to hand in _one_ Jupyter notebook (this notebook) with their solution**\n",
    "- **The hand-in of the notebook is due 2019-10-13, 23:59 on DTU Inside**\n",
    "\n",
    "#### Your solution\n",
    "- **Your solution should be in Python**\n",
    "- **For each question you may use as many cells for your solution as you like**\n",
    "- **You should document your solution and explain the choices you've made (for example by using multiple cells and use Markdown to assist the reader of the notebook)**\n",
    "- **You should not remove the problem statements, and you should not modify the structure of the notebook**\n",
    "- **Your notebook should be runnable, i.e., clicking [>>] in Jupyter should generate the result that you want to be assessed**\n",
    "- **You are not expected to use machine learning to solve any of the exercises**\n",
    "- **You will be assessed according to correctness and readability of your code, choice of solution, choice of tools and libraries, and documentation of your solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Your team has been hired by the company X as data scientists. X makes gadgets for a wide range of industrial and commercial clients.\n",
    "\n",
    "As in-house data scientists, your teams first task, as per request from your new boss, is to optimize business operations. You have decided that a good first step would be to analyze the companys historical sales data to gain a better understanding of where profit is coming from. It may also reveal some low hanging fruit in terms of business opportunities.\n",
    "\n",
    "To get started, you have called the IT department to get access to the customer and sales transactions database. To your horror you've been told that such a database doens't exist, and the only record of sales transactions is kept by John from finance in an Excel spreadsheet. So you've emailed John asking for a CSV dump of the spreadsheet...\n",
    "\n",
    "In this project you need to clean the data you got from John, enrich it with further data, prepare a database for the data, and do some data analysis. The project is comprised of five parts. They are intended to be solved in the order they appear, but it is highly recommended that you read through all of them and devise an overall strategy before you start implementing anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Cleaning the data\n",
    "John has emailed you the following link to the CSV dump you requested.\n",
    "\n",
    "- [transactions.csv](https://raw.githubusercontent.com/patrickcording/02807-comp-tools/master/docker/work/data/transactions.csv)\n",
    "\n",
    "It seems as though he has been a bit sloppy when keeping the records. \n",
    "\n",
    "In this part you should:\n",
    "- Explain what the data is\n",
    "- Clean it to prepare it for inserting into a database and doing data analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by fetching the data, checking the data types and the first few lines to get a general feeling for what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part       object\n",
      "company    object\n",
      "country    object\n",
      "city       object\n",
      "price      object\n",
      "date       object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54868-5165</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>784.79€</td>\n",
       "      <td>2016-01-02 00:01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60505-2867</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>187.99€</td>\n",
       "      <td>2016-01-02 00:05:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24385-268</td>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>221.73€</td>\n",
       "      <td>2016-01-02 00:18:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76117-001</td>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Annecy</td>\n",
       "      <td>1075.82€</td>\n",
       "      <td>2016-01-02 02:32:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44946-1046</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>412.55€</td>\n",
       "      <td>2016-01-02 04:51:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16729-167</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>359.52€</td>\n",
       "      <td>2016-01-02 07:20:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52125-444</td>\n",
       "      <td>Voomm</td>\n",
       "      <td>France</td>\n",
       "      <td>Paris</td>\n",
       "      <td>266.62€</td>\n",
       "      <td>2016-01-02 07:40:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>43419-018</td>\n",
       "      <td>Buzzbean</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Düsseldorf</td>\n",
       "      <td>103.45€</td>\n",
       "      <td>2016-01-02 08:57:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54092-515</td>\n",
       "      <td>Zooxo</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>£704.94</td>\n",
       "      <td>2016-01-02 09:09:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24286-1562</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>317.65€</td>\n",
       "      <td>2016-01-02 11:01:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         part        company         country          city     price  \\\n",
       "0  54868-5165  Chatterbridge           Spain     Barcelona   784.79€   \n",
       "1  60505-2867           Lajo          Greece  Thessaloniki   187.99€   \n",
       "2   24385-268      Flipstorm          Greece        Athens   221.73€   \n",
       "3   76117-001    Twitterbeat          France        Annecy  1075.82€   \n",
       "4  44946-1046  Chatterbridge           Spain     Barcelona   412.55€   \n",
       "5   16729-167  Chatterbridge           Spain     Barcelona   359.52€   \n",
       "6   52125-444          Voomm          France         Paris   266.62€   \n",
       "7   43419-018       Buzzbean         Germany    Düsseldorf   103.45€   \n",
       "8   54092-515          Zooxo  United Kingdom        London   £704.94   \n",
       "9  24286-1562           Lajo          Greece  Thessaloniki   317.65€   \n",
       "\n",
       "                  date  \n",
       "0  2016-01-02 00:01:05  \n",
       "1  2016-01-02 00:05:26  \n",
       "2  2016-01-02 00:18:30  \n",
       "3  2016-01-02 02:32:30  \n",
       "4  2016-01-02 04:51:55  \n",
       "5  2016-01-02 07:20:59  \n",
       "6  2016-01-02 07:40:37  \n",
       "7  2016-01-02 08:57:57  \n",
       "8  2016-01-02 09:09:01  \n",
       "9  2016-01-02 11:01:32  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('transactions.csv')\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consists of:\n",
    "- Part serial number\n",
    "- Company name\n",
    "- Company location, country\n",
    "- Company location, city\n",
    "- Price of the part\n",
    "- Date of transaction\n",
    "\n",
    "Apparently there are some typos in a couple of dates that need to be fixed before they can be converted to datetime format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    try:\n",
    "        pd.to_datetime(df.date[i])\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Incorrect data format: \", df.date[i], ' row: ', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ValueError: ('Incorrect data format: ', '2016-06-32 07:22:28', ' row: ', 3539)\n",
    "# ValueError: ('Incorrect data format: ', '2016-06-32 08:08:48', ' row: ', 3540)\n",
    "df.date[3539] = '2016-06-30 07:22:28'\n",
    "df.date[3540] = '2016-06-30 08:08:48'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then check how many unique values we have in each column and whether there are any missing values or typos. We also put date into a proper datetime format in order to get earliest and latest date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows:  20568 \n",
      "\n",
      "unique parts:  101\n",
      "nan:  10 \n",
      "\n",
      "['Spain' 'Greece' 'France' 'Germany' 'United Kingdom' 'Portugal'\n",
      " 'United States' 'Netherlands' 'Japan' 'Switzerland' nan]\n",
      "nan:  2171 \n",
      "\n",
      "['Barcelona' 'Thessaloniki' 'Athens' 'Annecy' 'Paris' 'Düsseldorf'\n",
      " 'London' 'Braga' 'Nanterre' 'Amadora' 'New York' 'Arnhem' 'Nice' 'Lisbon'\n",
      " 'Amsterdam' 'Porto' 'Boston' 'Niihama' 'Almada' 'Aranhas' 'Heraklion'\n",
      " 'Amiens' 'Patras' 'Arcueil' 'Lyon' 'Asaka' 'Champagnole' 'Zürich' nan\n",
      " 'Monção' 'Vila Fria']\n",
      "nan:  33 \n",
      "\n",
      "['Chatterbridge' 'Lajo' 'Flipstorm' 'Twitterbeat' 'Voomm' 'Buzzbean'\n",
      " 'Zooxo' 'Brainsphere' 'Thoughtmix' 'Wordify' 'Teklist' 'Avaveo' 'Ntags'\n",
      " 'Innojam' 'Shufflebeat' 'Zoonder' 'Kanoodle' 'Gabcube' 'Roodel'\n",
      " 'Riffpath' 'Eimbee' 'Yozio' 'Rhycero' 'Realpoint' 'Gabtune' 'Bubblemix'\n",
      " 'Gevee' 'Tagtune' 'Ntagz' ' -' ' a' 'aa']\n",
      "company nan:  0 \n",
      "\n",
      "price nan:  1\n",
      "date nan:  0 \n",
      "\n",
      "price in €:  17279\n",
      "price in £:  1672\n",
      "price in $:  20567\n",
      "price in ¥:  181\n",
      "undefined price:  10 \n",
      "\n",
      "date min:  2016-01-02 00:01:05\n",
      "date max:  2019-05-14 22:48:39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8683</th>\n",
       "      <td>49349-820</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>-</td>\n",
       "      <td>2017-03-03 15:24:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8684</th>\n",
       "      <td>10267-2529</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>-</td>\n",
       "      <td>2017-03-03 18:07:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8685</th>\n",
       "      <td>13537-259</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>-</td>\n",
       "      <td>2017-03-03 19:08:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8934</th>\n",
       "      <td>68084-172</td>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Annecy</td>\n",
       "      <td>void</td>\n",
       "      <td>2017-03-18 01:53:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10328</th>\n",
       "      <td>54868-0823</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>void</td>\n",
       "      <td>2017-06-02 06:49:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10329</th>\n",
       "      <td>41163-428</td>\n",
       "      <td>Avaveo</td>\n",
       "      <td>France</td>\n",
       "      <td>Nice</td>\n",
       "      <td>-</td>\n",
       "      <td>2017-06-02 07:04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10330</th>\n",
       "      <td>52959-433</td>\n",
       "      <td>Buzzbean</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Düsseldorf</td>\n",
       "      <td>-</td>\n",
       "      <td>2017-06-02 09:04:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11155</th>\n",
       "      <td>35356-325</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>na</td>\n",
       "      <td>2017-07-19 00:55:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11156</th>\n",
       "      <td>24385-268</td>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Annecy</td>\n",
       "      <td>na</td>\n",
       "      <td>2017-07-19 01:34:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11157</th>\n",
       "      <td>59779-601</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>na</td>\n",
       "      <td>2017-07-19 01:45:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             part        company   country        city price  \\\n",
       "8683    49349-820  Chatterbridge     Spain   Barcelona     -   \n",
       "8684   10267-2529     Thoughtmix  Portugal     Amadora     -   \n",
       "8685    13537-259          Ntags  Portugal      Lisbon     -   \n",
       "8934    68084-172    Twitterbeat    France      Annecy  void   \n",
       "10328  54868-0823  Chatterbridge     Spain   Barcelona  void   \n",
       "10329   41163-428         Avaveo    France        Nice     -   \n",
       "10330   52959-433       Buzzbean   Germany  Düsseldorf     -   \n",
       "11155   35356-325     Thoughtmix  Portugal     Amadora    na   \n",
       "11156   24385-268    Twitterbeat    France      Annecy    na   \n",
       "11157   59779-601     Thoughtmix  Portugal     Amadora    na   \n",
       "\n",
       "                 datetime  \n",
       "8683  2017-03-03 15:24:39  \n",
       "8684  2017-03-03 18:07:56  \n",
       "8685  2017-03-03 19:08:54  \n",
       "8934  2017-03-18 01:53:38  \n",
       "10328 2017-06-02 06:49:09  \n",
       "10329 2017-06-02 07:04:35  \n",
       "10330 2017-06-02 09:04:46  \n",
       "11155 2017-07-19 00:55:13  \n",
       "11156 2017-07-19 01:34:53  \n",
       "11157 2017-07-19 01:45:59  "
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('number of rows: ', len(df), '\\n')\n",
    "print('unique parts: ', len(df.part.unique()))\n",
    "print('nan: ', df.part.isna().sum(), '\\n')\n",
    "\n",
    "print(df.country.unique())\n",
    "print('nan: ', df.country.isna().sum(), '\\n')\n",
    "\n",
    "print(df.city.unique())\n",
    "print('nan: ', df.city.isna().sum(), '\\n')\n",
    "\n",
    "print(df.company.unique())\n",
    "print('company nan: ', df.company.isna().sum(), '\\n')\n",
    "\n",
    "print('price nan: ', df.price.isna().sum())\n",
    "print('date nan: ', df.date.isna().sum(), '\\n')\n",
    "\n",
    "print('price in €: ', len(df[df['price'].str.contains(\"€\")==True]))\n",
    "print('price in £: ', len(df[df['price'].str.contains(\"£\")==True]))\n",
    "print('price in $: ', len(df[df['price'].str.contains(\"$\")==True]))\n",
    "print('price in ¥: ', len(df[df['price'].str.contains(\"¥\")==True]))\n",
    "print('undefined price: ', len(df[df['price'].str.contains(\"[£$¥€]\")==False]), '\\n')\n",
    "\n",
    "df['datetime'] = pd.to_datetime(df.date)\n",
    "print('date min: ', df.datetime.min())\n",
    "print('date max: ', df.datetime.max())\n",
    "df.drop(['date'], inplace=True, axis=1)\n",
    "\n",
    "df[df['price'].str.contains(\"[£$¥€]\")==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issues with data:\n",
    "- Missing values in part, country, city and price **✔**-ish (What should we do with part?)\n",
    "- Typos in country and city **✔**\n",
    "- Germany/Tyskland, United States/US, Portugal/Portuga **✔**\n",
    "- Typos in date (already fixed) **✔**\n",
    "- Prices are in different currencies\n",
    "- Some prices unidentified **✔**-ish\n",
    "- Typos and nonsense company names **✔**\n",
    "\n",
    "#### Cleanup:\n",
    "Lets start with fixing typos in company, country and city. The correct currency for four rows can be deduced country/city. Rows with missing company and/or price are removed since without that the data is of very limited use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df # df cleaned\n",
    "\n",
    "dfc['company'] = df['company'].replace({'Laj0':'Lajo','Zooxo.':'Zooxo','Thoughtmixz':'Thoughtmix'})\n",
    "dfc['country'] = df['country'].replace({'Tyskland':'Germany', 'US':'United States', 'Portuga':'Portugal'})\n",
    "dfc['city'] = df['city'].replace({'Amadora\\t':'Amadora'})\n",
    "\n",
    "dfc = dfc[dfc.company != ' -']\n",
    "dfc = dfc[dfc.company != ' a']\n",
    "dfc = dfc[dfc.company != 'aa']\n",
    "\n",
    "dfc = dfc[dfc.price != '-']\n",
    "dfc = dfc[dfc.price != 'void']\n",
    "dfc = dfc[dfc.price != 'na']\n",
    "dfc = dfc[dfc.price.isna()==False]\n",
    "\n",
    "dfc.iloc[[2414],[4]] = dfc.iloc[[2414],[4]] + '€'\n",
    "dfc.iloc[[2415],[4]] = dfc.iloc[[2415],[4]] + '€'\n",
    "dfc.iloc[[2526],[4]] = dfc.iloc[[2526],[4]] + '€'\n",
    "dfc.iloc[[2528],[4]] = dfc.iloc[[2528],[4]] + '€'\n",
    "\n",
    "# dfc[dfc['price'].str.contains(\"[£$¥€]\")==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing city values are recovered by comparing rows with same company and the missing country values are likewise deduced from the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc['city'] = dfc['city'].fillna(dfc['company'].map({\n",
    "    'Brainsphere':'Braga', \n",
    "    'Shufflebeat':'Porto',\n",
    "    'Ntags':'Lisbon',\n",
    "    'Thoughtmix':'Amadora',\n",
    "    'Yozio':'Patras',\n",
    "    'Twitterbeat':'Annecy',\n",
    "    'Zooxo':'London',\n",
    "    'Zoonder':'Boston',\n",
    "    'Teklist':'Arnhem',\n",
    "    'Wordify':'New York',\n",
    "    'Kanoodle':'Niihama' \n",
    "}))\n",
    "\n",
    "dfc['country'] = dfc['country'].fillna(dfc['city'].map({\n",
    "    'Arnhem':'Netherlands',\n",
    "    'Braga':'Portugal',\n",
    "    'Düsseldorf':'Germany',\n",
    "    'Annecy':'France',\n",
    "    'Heraklion':'Greece',\n",
    "    'Barcelona':'Spain',\n",
    "    'Lisbon':'Portugal',\n",
    "    'Athens':'Greece',\n",
    "    'Amadora':'Portugal',\n",
    "    'Aranhas':'Portugal',\n",
    "    'New York':'United States',\n",
    "    'Patras':'Greece',\n",
    "    'Amiens':'France',\n",
    "    'Almada':'Portugal',\n",
    "    'Boston':'United States',\n",
    "    'Porto':'Portugal',\n",
    "    'Paris':'France',\n",
    "    'Nice':'France',\n",
    "    'London':'United Kingdom',\n",
    "    'Niihama':'Japan',\n",
    "    'Asaka':'Japan',\n",
    "    'Nanterre':'France',\n",
    "    'Arcueil':'France',\n",
    "    'Lyon':'France',\n",
    "    'Thessaloniki':'Greece',\n",
    "    'Amsterdam':'Netherlands',\n",
    "    'Champagnole':'France',\n",
    "    'Zürich':'Germany'\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The price is then extracted and placed in a new column corresponding to the currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17279\n"
     ]
    }
   ],
   "source": [
    "dfc['eur'] = np.where(dfc['price'].str.contains(\"€\")==True, dfc['price'].map(lambda x: x.lstrip('€').rstrip('€')), None)\n",
    "dfc['usd'] = np.where(dfc['price'].str.contains(\"\\$\")==True, dfc['price'].map(lambda x: x.lstrip('$').rstrip('$')), None)\n",
    "dfc['gbp'] = np.where(dfc['price'].str.contains(\"£\")==True, dfc['price'].map(lambda x: x.lstrip('£').rstrip('£')), None)\n",
    "dfc['yen'] = np.where(dfc['price'].str.contains(\"¥\")==True, dfc['price'].map(lambda x: x.lstrip('¥').rstrip('¥')), None)\n",
    "\n",
    "dfc['eur'] = dfc['eur'].astype(float)\n",
    "dfc['usd'] = dfc['usd'].astype(float)\n",
    "dfc['gbp'] = dfc['gbp'].astype(float)\n",
    "dfc['yen'] = dfc['yen'].astype(float)\n",
    "\n",
    "#dfc.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chatterbridge' 'Lajo' 'Flipstorm' 'Twitterbeat' 'Voomm' 'Buzzbean'\n",
      " 'Zooxo' 'Brainsphere' 'Thoughtmix' 'Wordify' 'Teklist' 'Avaveo' 'Ntags'\n",
      " 'Innojam' 'Shufflebeat' 'Zoonder' 'Kanoodle' 'Gabcube' 'Roodel'\n",
      " 'Riffpath' 'Eimbee' 'Yozio' 'Rhycero' 'Realpoint' 'Gabtune' 'Bubblemix'\n",
      " 'Gevee' 'Tagtune' 'Ntagz'] \n",
      "\n",
      "['Spain' 'Greece' 'France' 'Germany' 'United Kingdom' 'Portugal'\n",
      " 'United States' 'Netherlands' 'Japan' 'Switzerland'] \n",
      "\n",
      "['Barcelona' 'Thessaloniki' 'Athens' 'Annecy' 'Paris' 'Düsseldorf'\n",
      " 'London' 'Braga' 'Nanterre' 'Amadora' 'New York' 'Arnhem' 'Nice' 'Lisbon'\n",
      " 'Amsterdam' 'Porto' 'Boston' 'Niihama' 'Almada' 'Aranhas' 'Heraklion'\n",
      " 'Amiens' 'Patras' 'Arcueil' 'Lyon' 'Asaka' 'Champagnole' 'Zürich'\n",
      " 'Monção' 'Vila Fria'] \n",
      "\n",
      "10\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#print(dfc.part.unique(), '\\n')\n",
    "print(dfc.company.unique(), '\\n')\n",
    "print(dfc.country.unique(), '\\n')\n",
    "print(dfc.city.unique(), '\\n')\n",
    "\n",
    "print(len(dfc[dfc.part.isna()==True]))\n",
    "print(len(dfc[dfc.company.isna()==True]))\n",
    "print(len(dfc[dfc.country.isna()==True]))\n",
    "print(len(dfc[dfc.city.isna()==True]))\n",
    "print(len(dfc[dfc.price.isna()==True]))\n",
    "print(len(dfc[dfc.datetime.isna()==True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create column for each currency and insert them, fix missing country/city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Enriching the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common task for a data scientists is to combine or enrich data from internal sources with data available from external sources. The purpose of this can be either to fix issues with the data or to make it easier to derive insights from the data.\n",
    "\n",
    "In this part you should enrich your data with data from at least one external source. You may look to part 4 for some  inspiration as to what is required. Your solution should be automated, i.e., you can not ask the reader of your notebook to download any data manually. You should argue why and what you expect to achieve by the enrichments you are doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should probably have a column for each currency and fill in the gaps using exchange rate info from the api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Creating a database\n",
    "Storing data in a relational database has the advantages that it is persistent, fast to query, and it will be easier access for other employees at Weyland-Yutani.\n",
    "\n",
    "In this part you should:\n",
    "- Create a database and table(s) for the data\n",
    "- Insert data into the tables\n",
    "\n",
    "You may use SQLite locally to do this. You should argue why you choose to store your data the way you do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explain, insert data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('project1.sqlite')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('DROP TABLE IF EXISTS trans')\n",
    "conn.commit()\n",
    "c.execute('DROP TABLE IF EXISTS part')\n",
    "conn.commit()\n",
    "c.execute('DROP TABLE IF EXISTS city')\n",
    "conn.commit()\n",
    "c.execute('DROP TABLE IF EXISTS country')\n",
    "conn.commit()\n",
    "c.execute('DROP TABLE IF EXISTS price')\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('project1.sqlite')\n",
    "c = conn.cursor()\n",
    "\n",
    "query = '''\n",
    "CREATE TABLE IF NOT EXISTS trans(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    part_id INTEGER,\n",
    "    company_id INTEGER,\n",
    "    country_id INTEGER,\n",
    "    city_id INTEGER,\n",
    "    eur DECIMAL(13, 4),\n",
    "    usd DECIMAL(13, 4),\n",
    "    gbp DECIMAL(13, 4),\n",
    "    yen DECIMAL(13, 4),\n",
    "    transaction_date DATETIME,\n",
    "    FOREIGN KEY(part_id) REFERENCES part(id),\n",
    "    FOREIGN KEY(city_id) REFERENCES city(id),\n",
    "    FOREIGN KEY(country_id) REFERENCES country(id)\n",
    ")\n",
    "'''\n",
    "\n",
    "c.execute('CREATE TABLE IF NOT EXISTS part(id INTEGER PRIMARY KEY, serial VARCHAR(50))')\n",
    "conn.commit()\n",
    "\n",
    "c.execute('CREATE TABLE IF NOT EXISTS company(id INTEGER PRIMARY KEY, name VARCHAR(50))')\n",
    "conn.commit()\n",
    "\n",
    "c.execute('CREATE TABLE IF NOT EXISTS country(id INTEGER PRIMARY KEY, name VARCHAR(50))')\n",
    "conn.commit()\n",
    "\n",
    "c.execute('CREATE TABLE IF NOT EXISTS city(id INTEGER PRIMARY KEY, name VARCHAR(50))')\n",
    "conn.commit()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Analyzing the data\n",
    "You are now ready to analyze the data. Your goal is to gain some actionable business insights to present to your boss. \n",
    "\n",
    "In this part, you should ask some questions and try to answer them based on the data. You should write SQL queries to retrieve the data. For each question, you should state why it is relevant and what you expect to find.\n",
    "\n",
    "To get you started, you should prepare answers to the following questions. You should add more questions.\n",
    "#### Who are the most profitable clients?\n",
    "Knowing which clients that generate the most revenue for the company will assist your boss in distributing customer service ressources.\n",
    "\n",
    "#### Are there any clients for which profit is declining?\n",
    "Declining profit from a specific client may indicate that the client is disatisfied with the product. Gaining a new client is often much more work than retaining one. Early warnings about declining profit may help your boss fighting customer churn.\n",
    "\n",
    "\n",
    "Remember, you are taking this to your new boss, so think about how you present the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Performance\n",
    "Your boss is very impressed with what you have achieved in less than two weeks, and he would like to take your idea of storing the customer and sales data in a relational database to production. However, John is concerned that the solution will not scale. His experience is telling him that you will see many occurrences of the following queries.\n",
    "\n",
    "- Show all sales to company X between time $t_1$ and time $t_2$\n",
    "- Show the latest X sales in the database\n",
    "- Show total sales per company per day\n",
    "\n",
    "Show that Johns concern is not justified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concerns of a massive and therefore slow database? Fix with indexes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
